{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110bd90c-bc3c-4053-aac8-99973f74be68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1 Million MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42cff8a9-7b99-4037-ba01-ab0c90fe5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------------------------------------\n",
    "# Residual Block\n",
    "# ---------------------------------------\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_feats, num_feats, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(num_feats, num_feats, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "# ---------------------------------------\n",
    "# Single-Scale Deblurring Network\n",
    "# ---------------------------------------\n",
    "class SingleScaleDeblurNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_feats=64, num_blocks=8):\n",
    "        super().__init__()\n",
    "        self.head = nn.Conv2d(in_channels, num_feats, kernel_size=3, padding=1)\n",
    "        self.body = nn.Sequential(*[ResBlock(num_feats) for _ in range(num_blocks)])\n",
    "        self.tail = nn.Conv2d(num_feats, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.head(x)\n",
    "        feat = self.body(feat)\n",
    "        out = self.tail(feat)\n",
    "        return out\n",
    "\n",
    "# ---------------------------------------\n",
    "# Multi-Scale Deblurring Network (DeepDeblurMS)\n",
    "# ---------------------------------------\n",
    "class DeepDeblurMS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Each stage expects concatenated inputs â†’ 6 channels: [blur, upsampled_output]\n",
    "        self.coarse_net = SingleScaleDeblurNet(in_channels=6)\n",
    "        self.middle_net = SingleScaleDeblurNet(in_channels=6)\n",
    "        self.fine_net = SingleScaleDeblurNet(in_channels=6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Create image pyramid\n",
    "        x_half = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "        x_quarter = F.interpolate(x_half, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Coarse scale input: duplicate x_quarter to simulate [blur, blur]\n",
    "        coarse_input = torch.cat([x_quarter, x_quarter], dim=1)\n",
    "        coarse_out = self.coarse_net(coarse_input)\n",
    "        up_coarse = F.interpolate(coarse_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Middle scale input: [blur_half, upsampled_coarse]\n",
    "        mid_input = torch.cat([x_half, up_coarse], dim=1)\n",
    "        mid_out = self.middle_net(mid_input)\n",
    "        up_mid = F.interpolate(mid_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Fine scale input: [blur_full, upsampled_middle]\n",
    "        fine_input = torch.cat([x, up_mid], dim=1)\n",
    "        fine_out = self.fine_net(fine_input)\n",
    "\n",
    "        return fine_out, mid_out, coarse_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78926dc8-3c9f-43ed-92b6-3662af2ab987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# --- Config ---\n",
    "model_path = \"full_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(model_path, map_location=device)\n",
    "model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd8bbf8-b8e3-427b-838e-87bd3af58d98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model 2 (5 Mil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23596031-7f65-4929-9874-df7326f97210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Simple Attention ---\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // 8, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // 8, channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.attn(x)\n",
    "\n",
    "# --- Residual Block ---\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_feats, num_feats, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(num_feats, num_feats, 3, padding=1)\n",
    "        self.attn = SimpleAttention(num_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out = self.attn(out)\n",
    "        return x + out\n",
    "\n",
    "# --- Single Scale Net ---\n",
    "class SingleScaleDeblurNetTiny(nn.Module):\n",
    "    def __init__(self, in_channels, num_feats=64, num_blocks=6):\n",
    "        super().__init__()\n",
    "        self.head = nn.Conv2d(in_channels, num_feats, kernel_size=3, padding=1)\n",
    "        self.body = nn.Sequential(*[ResBlock(num_feats) for _ in range(num_blocks)])\n",
    "        self.tail = nn.Conv2d(num_feats, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.head(x)\n",
    "        feat = self.body(feat)\n",
    "        out = self.tail(feat)\n",
    "        return out\n",
    "\n",
    "# --- Multi-Scale Deblur Net ---\n",
    "class DeepDeblurMS_v2_Efficient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.coarse_net = SingleScaleDeblurNetTiny(in_channels=6, num_feats=48, num_blocks=4)\n",
    "        self.middle_net = SingleScaleDeblurNetTiny(in_channels=6, num_feats=64, num_blocks=6)\n",
    "        self.fine_net = SingleScaleDeblurNetTiny(in_channels=6, num_feats=96, num_blocks=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_half = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "        x_quarter = F.interpolate(x_half, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "        coarse_input = torch.cat([x_quarter, x_quarter], dim=1)\n",
    "        coarse_out = self.coarse_net(coarse_input)\n",
    "        up_coarse = F.interpolate(coarse_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        mid_input = torch.cat([x_half, up_coarse], dim=1)\n",
    "        mid_out = self.middle_net(mid_input)\n",
    "        up_mid = F.interpolate(mid_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        fine_input = torch.cat([x, up_mid], dim=1)\n",
    "        fine_out = self.fine_net(fine_input)\n",
    "\n",
    "        return fine_out, mid_out, coarse_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621d98a-71bc-42db-916f-13be522aaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# --- Config ---\n",
    "model_path = \"5M_model_retrain.pth\"\n",
    "# blur_root = \"train_images_blur\"\n",
    "# gt_root = \"train_images\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.load(model_path, map_location=device)\n",
    "model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a2c9e-384a-40eb-bd57-b5ede565a971",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model 3 (10-14 Mil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ecc33b-e90d-4127-81c9-c35c9ffa0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------------------------------------\n",
    "# Simple Attention Block\n",
    "# ---------------------------------------\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // 8, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // 8, channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.attn(x)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Residual Block with Attention\n",
    "# ---------------------------------------\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_feats, num_feats, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(num_feats, num_feats, 3, padding=1)\n",
    "        self.attn = SimpleAttention(num_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out = self.attn(out)\n",
    "        return x + out\n",
    "\n",
    "# ---------------------------------------\n",
    "# Single-Scale Deblurring Network\n",
    "# ---------------------------------------\n",
    "class SingleScaleDeblurNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_feats=128, num_blocks=16):\n",
    "        super().__init__()\n",
    "        self.head = nn.Conv2d(in_channels, num_feats, kernel_size=3, padding=1)\n",
    "        self.body = nn.Sequential(*[ResBlock(num_feats) for _ in range(num_blocks)])\n",
    "        self.tail = nn.Conv2d(num_feats, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.head(x)\n",
    "        feat = self.body(feat)\n",
    "        out = self.tail(feat)\n",
    "        return out\n",
    "\n",
    "# ---------------------------------------\n",
    "# Multi-Scale Deblurring Network (DeepDeblurMS_v2)\n",
    "# ---------------------------------------\n",
    "class DeepDeblurMS_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Each stage expects concatenated inputs â†’ 6 channels: [blur, upsampled_output]\n",
    "        self.coarse_net = SingleScaleDeblurNet(in_channels=6)\n",
    "        self.middle_net = SingleScaleDeblurNet(in_channels=6)\n",
    "        self.fine_net = SingleScaleDeblurNet(in_channels=6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Create image pyramid\n",
    "        x_half = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "        x_quarter = F.interpolate(x_half, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Coarse scale input: [blur_quarter, blur_quarter]\n",
    "        coarse_input = torch.cat([x_quarter, x_quarter], dim=1)\n",
    "        coarse_out = self.coarse_net(coarse_input)\n",
    "        up_coarse = F.interpolate(coarse_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Middle scale input: [blur_half, upsampled_coarse]\n",
    "        mid_input = torch.cat([x_half, up_coarse], dim=1)\n",
    "        mid_out = self.middle_net(mid_input)\n",
    "        up_mid = F.interpolate(mid_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Fine scale input: [blur_full, upsampled_middle]\n",
    "        fine_input = torch.cat([x, up_mid], dim=1)\n",
    "        fine_out = self.fine_net(fine_input)\n",
    "\n",
    "        return fine_out, mid_out, coarse_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7e2e4-6a56-4c1c-a196-ee841c8a06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# --- Config ---\n",
    "model_path = \"full_model_14G.pth\"\n",
    "# blur_root = \"train_images_blur\"\n",
    "# gt_root = \"train_images\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load Model ---\n",
    "model = torch.load(model_path, map_location=device)\n",
    "model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca84aa-4fa4-4131-8d4c-5a61bb73132f",
   "metadata": {},
   "source": [
    "## Loss function/display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29673ac-d7b3-4759-8779-3534ab09c82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
